name: Deploy SAS Model to Databricks

on:
  push:
    branches:
      - main
    paths:
      - "data/**"
      - "models/**"
      - "scripts/**"

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: üì• Checkout Repository
        uses: actions/checkout@v3

      - name: üõ†Ô∏è Print Environment Variables (Debug)
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_JOB_ID: ${{ secrets.DATABRICKS_JOB_ID }}
        run: |
          echo "üîπ Checking Databricks Environment Variables..."
          echo "DATABRICKS_HOST is set (masked)"
          echo "DATABRICKS_JOB_ID is set to: ${DATABRICKS_JOB_ID}"

      - name: üìÇ Install Databricks CLI
        run: |
          pip install --upgrade databricks-cli
          databricks --version

      - name: üîç Configure Databricks CLI
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          echo "üîπ Setting up Databricks CLI..."

          if [[ -z "$DATABRICKS_HOST" ]]; then
            echo "‚ùå ERROR: DATABRICKS_HOST is not set!" && exit 1
          fi
          if [[ -z "$DATABRICKS_TOKEN" ]]; then
            echo "‚ùå ERROR: DATABRICKS_TOKEN is not set!" && exit 1
          fi

          echo "üîπ Exporting Databricks credentials..."
          export DATABRICKS_HOST=$DATABRICKS_HOST
          export DATABRICKS_TOKEN=$DATABRICKS_TOKEN

          echo "üîπ Testing Databricks connection..."
          databricks clusters list
        shell: bash

      - name: üì§ Upload Data to Databricks
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          echo "üöÄ Uploading dataset.csv..."
          DATABRICKS_HOST=$DATABRICKS_HOST DATABRICKS_TOKEN=$DATABRICKS_TOKEN databricks fs cp --overwrite data/dataset.csv dbfs:/mnt/datasets/dataset.csv
          echo "‚úÖ dataset.csv uploaded!"

          echo "üöÄ Uploading model_predictions.csv..."
          DATABRICKS_HOST=$DATABRICKS_HOST DATABRICKS_TOKEN=$DATABRICKS_TOKEN databricks fs cp --overwrite data/model_predictions.csv dbfs:/mnt/datasets/model_predictions.csv
          echo "‚úÖ model_predictions.csv uploaded!"
        shell: bash

      - name: üì§ Upload Scripts to Databricks
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          echo "üöÄ Uploading data_preparation.py..."
          DATABRICKS_HOST=$DATABRICKS_HOST DATABRICKS_TOKEN=$DATABRICKS_TOKEN databricks workspace import --format SOURCE --language PYTHON scripts/data_preparation.py /Workspace/data_preparation.py
          echo "‚úÖ data_preparation.py uploaded!"

          echo "üöÄ Uploading feature_engineering.py..."
          DATABRICKS_HOST=$DATABRICKS_HOST DATABRICKS_TOKEN=$DATABRICKS_TOKEN databricks workspace import --format SOURCE scripts/feature_engineering.py /Workspace/feature_engineering.py
          echo "‚úÖ feature_engineering.py uploaded!"

          echo "üöÄ Uploading train_model.py..."
          DATABRICKS_HOST=$DATABRICKS_HOST DATABRICKS_TOKEN=$DATABRICKS_TOKEN databricks workspace import --format SOURCE models/train_model.py /Workspace/models/train_model.py
          echo "‚úÖ train_model.py uploaded!"
        shell: bash

      - name: üöÄ Run Databricks Job
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          DATABRICKS_JOB_ID: ${{ secrets.DATABRICKS_JOB_ID }}
        run: |
          echo "üîπ Running Databricks Job with ID: ${DATABRICKS_JOB_ID}"
          DATABRICKS_HOST=$DATABRICKS_HOST DATABRICKS_TOKEN=$DATABRICKS_TOKEN databricks jobs run-now --job-id ${DATABRICKS_JOB_ID}
        shell: bash
