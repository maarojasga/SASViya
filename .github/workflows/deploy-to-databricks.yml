name: Deploy SAS Model to Databricks

on:
  push:
    branches:
      - main
    paths:
      - 'data/**'
      - 'models/**'
      - 'scripts/**'

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v3

      - name: ğŸ› ï¸ Print Environment Variables (Debug)
        run: |
          echo "ğŸ”¹ Checking Databricks Environment Variables..."
          echo "DATABRICKS_HOST is set to: ${DATABRICKS_HOST}"
          echo "DATABRICKS_JOB_ID is set to: ${DATABRICKS_JOB_ID}"
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_JOB_ID: ${{ secrets.DATABRICKS_JOB_ID }}

      - name: ğŸ“‚ Install Databricks CLI
        run: |
          pip install databricks-cli
          databricks --version

      - name: ğŸ” Validate Databricks CLI Configuration
        run: |
          echo "ğŸ”¹ Configuring Databricks CLI..."
          if [[ -z "${{ secrets.DATABRICKS_HOST }}" ]]; then
            echo "âŒ ERROR: DATABRICKS_HOST is not set!" && exit 1
          fi
          if [[ -z "${{ secrets.DATABRICKS_TOKEN }}" ]]; then
            echo "âŒ ERROR: DATABRICKS_TOKEN is not set!" && exit 1
          fi
          databricks configure --host ${{ secrets.DATABRICKS_HOST }} --token ${{ secrets.DATABRICKS_TOKEN }}
          echo "âœ… Databricks CLI configured successfully!"

      - name: ğŸ“¤ Upload Data to Databricks
        run: |
          echo "ğŸš€ Uploading dataset.csv..."
          databricks fs cp --overwrite data/dataset.csv dbfs:/mnt/datasets/dataset.csv
          echo "âœ… dataset.csv uploaded!"
          
          echo "ğŸš€ Uploading model_predictions.csv..."
          databricks fs cp --overwrite data/model_predictions.csv dbfs:/mnt/datasets/model_predictions.csv
          echo "âœ… model_predictions.csv uploaded!"

      - name: ğŸ“¤ Upload Scripts to Databricks
        run: |
          echo "ğŸš€ Uploading data_preparation.py..."
          databricks workspace import --format SOURCE scripts/data_preparation.py /Workspace/data_preparation.py
          echo "âœ… data_preparation.py uploaded!"

          echo "ğŸš€ Uploading feature_engineering.py..."
          databricks workspace import --format SOURCE scripts/feature_engineering.py /Workspace/feature_engineering.py
          echo "âœ… feature_engineering.py uploaded!"

          echo "ğŸš€ Uploading logistic_regression.py..."
          databricks workspace import --format SOURCE models/logistic_regression.py /Workspace/logistic_regression.py
          echo "âœ… logistic_regression.py uploaded!"

      - name: ğŸš€ Run Notebook in Databricks
        run: |
          echo "ğŸ”¹ Running Databricks Job with ID: ${{ secrets.DATABRICKS_JOB_ID }}"
          databricks jobs run-now --job-id ${{ secrets.DATABRICKS_JOB_ID }}
