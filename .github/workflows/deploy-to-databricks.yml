name: Deploy SAS Model to Databricks

on:
  push:
    branches:
      - main
    paths:
      - "data/**"
      - "models/**"
      - "scripts/**"

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: üì• Checkout Repository
        uses: actions/checkout@v3

      - name: üõ†Ô∏è Print Environment Variables (Debug)
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_JOB_ID: ${{ secrets.DATABRICKS_JOB_ID }}
        run: |
          echo "üîπ Checking Databricks Environment Variables..."
          echo "DATABRICKS_HOST is set (masked)"
          echo "DATABRICKS_JOB_ID is set to: ${DATABRICKS_JOB_ID}"

      - name: üìÇ Install Databricks CLI
        run: |
          pip install --upgrade databricks-cli
          databricks --version

      - name: üîç Configure Databricks CLI
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          echo "üîπ Setting up Databricks CLI..."

          if [[ -z "$DATABRICKS_HOST" ]]; then
            echo "‚ùå ERROR: DATABRICKS_HOST is not set!" && exit 1
          fi
          if [[ -z "$DATABRICKS_TOKEN" ]]; then
            echo "‚ùå ERROR: DATABRICKS_TOKEN is not set!" && exit 1
          fi

          echo "üîπ Exporting Databricks credentials..."
          export DATABRICKS_HOST=$DATABRICKS_HOST
          export DATABRICKS_TOKEN=$DATABRICKS_TOKEN

          echo "üîπ Testing Databricks connection..."
          databricks clusters list
        shell: bash

      - name: üì§ Upload Data to Databricks
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          echo "üöÄ Uploading dataset.csv..."
          databricks fs cp --overwrite data/dataset.csv dbfs:/mnt/datasets/dataset.csv
          echo "‚úÖ dataset.csv uploaded!"

          echo "üöÄ Uploading model_predictions.csv..."
          databricks fs cp --overwrite data/model_predictions.csv dbfs:/mnt/datasets/model_predictions.csv
          echo "‚úÖ model_predictions.csv uploaded!"
        shell: bash

      - name: üì§ Upload Scripts to Databricks (Only if Not Exists)
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          upload_script() {
            local script_path=$1
            local workspace_path=$2

            echo "üîπ Checking if ${workspace_path} exists in Databricks..."
            if databricks workspace ls "$(dirname ${workspace_path})" | grep -q "$(basename ${workspace_path})"; then
              echo "‚úÖ ${workspace_path} already exists. Skipping upload."
            else
              echo "üöÄ Uploading ${script_path}..."
              databricks workspace import --format SOURCE --language PYTHON "${script_path}" "${workspace_path}"
              echo "‚úÖ ${workspace_path} uploaded successfully!"
            fi
          }

          # Subir archivos de scripts
          upload_script "scripts/data_preparation.py" "/Workspace/data_preparation.py"
          upload_script "scripts/feature_engineering.py" "/Workspace/feature_engineering.py"

          # CREAR CARPETA /Workspace/models/ SI NO EXISTE
          echo "üîπ Checking if /Workspace/models exists..."
          if ! databricks workspace ls /Workspace | grep -q "models"; then
            echo "üöÄ Creating /Workspace/models directory..."
            databricks workspace mkdirs /Workspace/models
            echo "‚úÖ /Workspace/models created!"
          else
            echo "‚úÖ /Workspace/models already exists."
          fi

          # Subir modelo de entrenamiento
          upload_script "models/train_model.py" "/Workspace/models/train_model.py"
        shell: bash

      - name: üöÄ Run Databricks Job
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          DATABRICKS_JOB_ID: ${{ secrets.DATABRICKS_JOB_ID }}
        run: |
          echo "üîπ Running Databricks Job with ID: ${DATABRICKS_JOB_ID}"
          databricks jobs run-now --job-id ${DATABRICKS_JOB_ID}
        shell: bash
